{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Categorization\n",
    "\n",
    "- 비슷한 뉴스를 어떻게 선정할까?\n",
    "- 뉴스들이 있다면 컴퓨터는 문자를 그대로 이해하지 못하기 때문에 문자를 숫자로 바꾸어야 한다.\n",
    "- 숫자로 '유사하다'는 어떻게 표현할까? '유사하다 = 가깝다'로 표현할 수 있다. 좌표평면에서 기본적으로 쓰이는 피타고라스의 정리를 통해 두 점이 가까운지 먼지를 알 수 있다. \n",
    "- 그래서 궁극적으로 하고 싶은 것은 문자를 숫자로, 숫자는 vector로 표현하고 싶은 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자 -> 숫자 -> Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자를 Vector로 - One-hot Encoding\n",
    "\n",
    "- 하나의 단어를 Vector의 Indox로 인식, 단어 존재시 1 없으면 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rome = [1,0,0,0,0,0,0,0,0,0]\n",
    "Paris = [0,1,0,0,0,0,0,0,0,0]\n",
    "Italy = [0,0,1,0,0,0,0,0,0,0]\n",
    "France = [0,0,0,1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "- 단어별로 인덱스를 부여해서, 한 문장(또는 문서)의 단어의 개수를 Vector로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Screen Shot 2018-08-15 at 7.17.55 PM.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유사성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance measure\n",
    "\n",
    "- 고등학교 때 배운 2차원 평면상 거리측정 방법들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Screen Shot 2018-08-15 at 7.20.56 PM.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidian distance\n",
    "\n",
    "- 피타고라스의 정리, 두 점 사이의 직선의 거리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Screen Shot 2018-08-15 at 7.23.17 PM.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine distance\n",
    "\n",
    "- 두 점 사이의 각도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Screen Shot 2018-08-15 at 7.23.27 PM.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 Euclidian distance보다는 Cosine distance를 더 많이 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "\n",
    "- 축구와 야구 선수들의 영문 기사를 분류해보자!\n",
    "- 1,2,3,4 야구 / 5,6,7,8 축구 (news_data 폴더 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "\n",
    "- 파일을 불러오기\n",
    "- 파일을 읽어서 단어사전 (corpus) 만들기\n",
    "- 단어별로 Index 만들기\n",
    "- 만들어진 인덱스로 문서별로 Bag of words vector 생성 - 비교하고자 하는 문서 비교하기\n",
    "- 얼마나 맞는지 측정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_file_list(dir_name):\n",
    "    return os.listdir(dir_name)\n",
    "\n",
    "print(len(get_file_list('news_data')))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dir_name = \"news_data\"\n",
    "    \n",
    "    file_list = get_file_list(dir_name)\n",
    "    file_list = [os.path.join(dir_name, file_name) \n",
    "                 for file_name in file_list]\n",
    "    print(len(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- os.listdir\n",
    "\n",
    "os.listdir을 이용하면 해당 디렉터리에 있는 파일들의 리스트를 가져오게 된다. 여기서 구해지는 파일 리스트는 파일명만 포함되어 있으므로 경로를 포함한 파일명을 구하기 위해서는 입력으로 받은 dirname을 앞에 덧붙여 주어야 한다.\n",
    "\n",
    "- os.path.join\n",
    "\n",
    "디렉터리와 파일들을 연결하려고 할 때 사용한다. 보통 /를 통해 join을 해주지만 python에서는 os.path.join을 통해 join을 해주어야 한다. os 모듈에 있는 os.path.join로 디렉터리를 포함한 전체 경로를 쉽게 가져올 수 있다.\n",
    "\n",
    "쉽게 말해 os.listdir을 통해 전체 파일들의 리스트를 가져와서, os.path.join을 통해 전체 경로를 연결하여 다시 전체 파일들의 리스트를 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일별로 내용읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conetents(file_list):\n",
    "    y_class = []\n",
    "    X_text = []\n",
    "\n",
    "    # baseball - 0, soccer - 1\n",
    "    class_dict = {\n",
    "        1: \"0\", 2: \"0\", 3:\"0\", 4:\"0\", 5:\"1\", 6:\"1\", 7:\"1\", 8:\"1\"}\n",
    "\n",
    "    for file_name in file_list:\n",
    "        try:\n",
    "            # cp949 - windows file (utf - mac, linux file)\n",
    "            f = open(file_name, \"r\",  encoding=\"cp949\")\n",
    "            \n",
    "            # os.sep[1] - file name only, split(\"_\")[0] - before underbar\n",
    "            # os.sep - Get directory separator\n",
    "            # ex. 1 in 1_Dae-Ho Lee walk-off homer gives Mariners ...\n",
    "            category = int(file_name.split(os.sep)[1].split(\"_\")[0])\n",
    "            \n",
    "            # print(file_name.split(os.sep))\n",
    "            # ex. ['news_data', '3_SEUNG-HWAN OH SHUTS DOWN TWINS IN FIRST SPRING ACTION.txt']\n",
    "            \n",
    "            # y_class is expressed as 0 class(baseball) and 1 class(soccer)\n",
    "            y_class.append(class_dict[category])\n",
    "            \n",
    "            # X_test is 1-dimensional list\n",
    "            X_text.append(f.read())\n",
    "            f.close()\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(e)\n",
    "            print(file_name)\n",
    "    return X_text, y_class\n",
    "\n",
    "# test\n",
    "X_text, y_class = get_conetents(file_list)\n",
    "# print(y_class)\n",
    "# print(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus 만들기 + 단어별 index 생성하기\n",
    "\n",
    "- Corpus란, text안에 있는 word들에 대한 index를 만들어주는 것. 각각의 word가 몇 번째 index에 속한다는 것을 선언해주는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imyours\n"
     ]
    }
   ],
   "source": [
    "# additional section\n",
    "def get_cleaned_text(text):\n",
    "    '''regular expression - eliminate meaningless sentence protection'''\n",
    "    import re\n",
    "    text = re.sub('\\W+','', text.lower() )\n",
    "    return text\n",
    "\n",
    "print(get_cleaned_text(\"I'm Yours\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 4024\n"
     ]
    }
   ],
   "source": [
    "def get_corpus_dict(text):\n",
    "    # 2-dimensional list\n",
    "    text = [sentence.split() for sentence in text]\n",
    "    \n",
    "    # 1-dimensioal list\n",
    "    cleaned_words = [get_cleaned_text(word) \n",
    "                    for words in text for word in words]\n",
    "\n",
    "    corpus_dict = dict()\n",
    "    for i, v in enumerate(set(cleaned_words)):\n",
    "        corpus_dict[v] = i\n",
    "    return corpus_dict\n",
    "\n",
    "corpus = get_corpus_dict(X_text)\n",
    "print(\"Number of words : {}\".format(len(corpus)))\n",
    "# print('corpus', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 set은 다음과 같은 2가지 큰 특징이 있다.\n",
    "\n",
    "- 중복을 허용하지 않는다.\n",
    "- 순서가 없다(Unordered).\n",
    "\n",
    "또한 리스트나 튜플은 순서가 있기(ordered) 때문에 인덱싱을 통해 자료형의 값을 얻을 수 있지만 set 자료형은 순서가 없기(unordered) 때문에 인덱싱으로 값을 얻을 수 없다. 만약 set 자료형에 저장된 값을 인덱싱으로 접근하려면 다음과 같이 리스트나 튜플로 변환한 후 해야 한다.\n",
    "\n",
    "위에서 set을 쓴 이유도 중복을 없애기 위해서 쓴 것이다. 단어들마다 index를 만들어주기 위해서 중복되는 단어들을 set을 통해 없앤 뒤에 for문을 통해 index를 만들어준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서별로 Bag of words vector 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_vector(text, corpus):\n",
    "    text = [sentence.split() for sentence in text]\n",
    "    \n",
    "    # 2-dimensional list\n",
    "    # The number that the words in the documents correspond to the index number in the corpus.\n",
    "    word_number_list = [[corpus[get_cleaned_text(word)] \n",
    "                         for word in words] for words in text]\n",
    "    # print('corpus', corpus)\n",
    "#     print('word_number_list', word_number_list)\n",
    "    \n",
    "    # 80 x 4024 matrices\n",
    "    X_vector = [[0 for _ in range(len(corpus))] \n",
    "                for _ in range(len(text))]\n",
    "#     print(X_vector[0])\n",
    "\n",
    "    # Check the number of words in one text\n",
    "    for i, text in enumerate(word_number_list):\n",
    "        for word_number in text:\n",
    "            X_vector[i][word_number] += 1\n",
    "    return X_vector\n",
    "\n",
    "# test\n",
    "corpus = get_corpus_dict(X_text)\n",
    "# print(get_count_vector(X_text, corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Screen Shot 2018-08-15 at 10.18.42 PM.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_cosine_similarity(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 v1, v2는 문서를 의미한다. 그러니까 얼마의 similarity score를 가지는 지를 표현하는 코드이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비교결과 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(X_vector, source):\n",
    "    source_vector = X_vector[source]\n",
    "    similarity_list = []\n",
    "    for target_vector in X_vector:\n",
    "        similarity_list.append(\n",
    "            get_cosine_similarity(source_vector, target_vector))\n",
    "    return similarity_list\n",
    "\n",
    "\n",
    "def get_top_n_similarity_news(similarity_score, n):\n",
    "    import operator\n",
    "    total_score = {i:v for i, v in enumerate(similarity_score)}\n",
    "#     print(\"total_score\\n\" + str(total_score))\n",
    "    sorted_total_score = sorted(total_score.items(), key=operator.itemgetter(1))\n",
    "    return list(reversed(sorted_total_score))[1:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_score\n",
      "{0: 0.422127681059035, 1: 1.0, 2: 0.560082394374579, 3: 0.2968763938415094, 4: 0.5514983941504927, 5: 0.6076835623757505, 6: 0.5060457507814917, 7: 0.6314062762993071, 8: 0.5421767411201769, 9: 0.427426276966268, 10: 0.5912746373712418, 11: 0.6029946996569844, 12: 0.7144117698730763, 13: 0.5189551148833238, 14: 0.5475429873588856, 15: 0.5643477968473063, 16: 0.47443968388194596, 17: 0.6009817862519662, 18: 0.3522531739514477, 19: 0.6582264823046564, 20: 0.47604248440179164, 21: 0.5306292591824382, 22: 0.4914523616067112, 23: 0.49193602225302246, 24: 0.5696030889639794, 25: 0.6232503314246413, 26: 0.5926674229884631, 27: 0.3687409228350686, 28: 0.671978067683249, 29: 0.6348050371984161, 30: 0.5770610597506486, 31: 0.542277551828845, 32: 0.4257576283238868, 33: 0.6063203769697062, 34: 0.5062393559988809, 35: 0.34700237194342054, 36: 0.344447481913586, 37: 0.6038924815196922, 38: 0.5142741232363717, 39: 0.6732690733648422, 40: 0.4847200928510529, 41: 0.5808629216843902, 42: 0.6309760786259462, 43: 0.5215586600424191, 44: 0.5799250500993886, 45: 0.3410988720085692, 46: 0.6485742886450424, 47: 0.5674707358752735, 48: 0.5738698972325784, 49: 0.5647356538417078, 50: 0.488348269371181, 51: 0.4787847221761729, 52: 0.6185479432609964, 53: 0.5059079592516773, 54: 0.5479610820823354, 55: 0.6135790137591519, 56: 0.37655920082643196, 57: 0.6073796229562909, 58: 0.5610738125652448, 59: 0.6321244224565635, 60: 0.5451130505007231, 61: 0.5029500559597238, 62: 0.6028807179495208, 63: 0.6528679963502718, 64: 0.6736825656806577, 65: 0.4643451288290275, 66: 0.5030421763327656, 67: 0.6149930408285731, 68: 0.5915474785446979, 69: 0.5800479884670575, 70: 0.4573457087375922, 71: 0.5258678898219074, 72: 0.4572513337017209, 73: 0.587445075846677, 74: 0.6032009672938331, 75: 0.598249043316643, 76: 0.5726144672220465, 77: 0.6165136055690399, 78: 0.5969152794421093, 79: 0.4187009363586748}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "X_vector = get_count_vector(X_text, corpus)\n",
    "source_number = 1\n",
    "test_similarity_score = get_similarity_score(X_vector, source_number)\n",
    "test_similarity_news = get_top_n_similarity_news(test_similarity_score, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(similarity_list, y_class, source_news):\n",
    "    source_class = y_class[source_news]\n",
    "#     print(similarity_list)\n",
    "#     print(sum([source_class == y_class[i[0]]\n",
    "#                 for i in similarity_list]))\n",
    "    return sum([source_class == y_class[i[0]] \n",
    "                for i in similarity_list]) / len(similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 4024\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dir_name = \"news_data\"\n",
    "    file_list = get_file_list(dir_name)\n",
    "    file_list = [os.path.join(dir_name, file_name) \n",
    "                 for file_name in file_list]\n",
    "\n",
    "    X_text, y_class = get_conetents(file_list)\n",
    "\n",
    "    corpus = get_corpus_dict(X_text)\n",
    "    print(\"Number of words : {0}\".format(len(corpus)))\n",
    "    X_vector = get_count_vector(X_text, corpus)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(80):\n",
    "        source_number = i\n",
    "        \n",
    "        # 80 x 80\n",
    "        similarity_score = get_similarity_score(X_vector, source_number)\n",
    "        \n",
    "        similarity_news = get_top_n_similarity_news(similarity_score, 5)\n",
    "        \n",
    "        accuracy_score = get_accuracy(similarity_news, y_class, source_number)\n",
    "        result.append(accuracy_score)\n",
    "    print(round((sum(result) / 80), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
